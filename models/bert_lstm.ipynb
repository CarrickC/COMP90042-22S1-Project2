{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# bert_model = \"vinai/bertweet-base\"\n",
    "bert_model = 'bert-base-uncased'\n",
    "# bert_model = 'google/electra-small-discriminator'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
    "bert = AutoModel.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. Can regularly rinsing your nose with saline...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30414</th>\n",
       "      <td>@rosierawle Tasha and I just little giggle at...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30415</th>\n",
       "      <td>@Kirstenjoyweiss @prestone85 @ldsknack I beli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30416</th>\n",
       "      <td>@rosierawle All good. Just been working out t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30417</th>\n",
       "      <td>@Kirstenjoyweiss @prestone85 @ldsknack Even t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30418</th>\n",
       "      <td>@LeeMcmaster77 @Kirstenjoyweiss @prestone85 @...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30419 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      5. Can regularly rinsing your nose with saline...      0\n",
       "1      5. Can regularly rinsing your nose with saline...      0\n",
       "2      5. Can regularly rinsing your nose with saline...      0\n",
       "3      5. Can regularly rinsing your nose with saline...      0\n",
       "4      5. Can regularly rinsing your nose with saline...      0\n",
       "...                                                  ...    ...\n",
       "30414   @rosierawle Tasha and I just little giggle at...      0\n",
       "30415   @Kirstenjoyweiss @prestone85 @ldsknack I beli...      0\n",
       "30416   @rosierawle All good. Just been working out t...      0\n",
       "30417   @Kirstenjoyweiss @prestone85 @ldsknack Even t...      0\n",
       "30418   @LeeMcmaster77 @Kirstenjoyweiss @prestone85 @...      0\n",
       "\n",
       "[30419 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "train = pd.read_csv('data/train/train_enrich.csv', delimiter = '\\t')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-19 Fact:\\nAre hand dryers effective in k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19 Fact:\\nAre hand dryers effective in k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@atruchecks when can we expect the result of m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@atruchecks when can we expect the result of m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@atruchecks when can we expect the result of m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10549</th>\n",
       "      <td>19 (including drugs, vaccines, therapies)?\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10550</th>\n",
       "      <td>19 (including drugs, vaccines, therapies)?\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10551</th>\n",
       "      <td>19 (including drugs, vaccines, therapies)?\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10552</th>\n",
       "      <td>19 (including drugs, vaccines, therapies)?\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10553</th>\n",
       "      <td>19 (including drugs, vaccines, therapies)?\\n\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10554 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "0      COVID-19 Fact:\\nAre hand dryers effective in k...      0\n",
       "1      COVID-19 Fact:\\nAre hand dryers effective in k...      0\n",
       "2      @atruchecks when can we expect the result of m...      0\n",
       "3      @atruchecks when can we expect the result of m...      0\n",
       "4      @atruchecks when can we expect the result of m...      0\n",
       "...                                                  ...    ...\n",
       "10549   19 (including drugs, vaccines, therapies)?\\n\\...      0\n",
       "10550   19 (including drugs, vaccines, therapies)?\\n\\...      0\n",
       "10551   19 (including drugs, vaccines, therapies)?\\n\\...      0\n",
       "10552   19 (including drugs, vaccines, therapies)?\\n\\...      0\n",
       "10553   19 (including drugs, vaccines, therapies)?\\n\\...      0\n",
       "\n",
       "[10554 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data = []\n",
    "dev_label = []\n",
    "dev = pd.read_csv('data/dev/dev_enrich.csv', delimiter = '\\t')\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10554/10554 [34:40<00:00,  5.07it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dev))):\n",
    "    text = dev.iloc[i]['text']\n",
    "    label = dev.iloc[i]['label']\n",
    "    dev_label.append(label)\n",
    "    s = tokenizer(text, padding='max_length', truncation=True)\n",
    "    dev_data.append(bert(torch.tensor((s['input_ids'])).unsqueeze(0), attention_mask = torch.tensor((s['attention_mask'])).unsqueeze(0)).last_hidden_state.tolist()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30419/30419 [11:34:55<00:00,  1.37s/it]  \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train))):\n",
    "    text = train.iloc[i]['text']\n",
    "    label = train.iloc[i]['label']\n",
    "    train_label.append(label)\n",
    "    s = tokenizer(text, padding='max_length', truncation=True)\n",
    "    train_data.append(bert(torch.tensor((s['input_ids'])).unsqueeze(0), attention_mask = torch.tensor((s['attention_mask'])).unsqueeze(0)).last_hidden_state.tolist()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30419/30419 [00:02<00:00, 13155.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train))):\n",
    "    label = train.iloc[i]['label']\n",
    "    train_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "train_file = open('data/train/train_basebert.csv', 'w', newline = '')\n",
    "train_dataset = csv.writer(train_file)\n",
    "train_dataset.writerows(train_data)\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# dev_file = open('data/dev/dev_matrix.csv', 'w', newline = '')\n",
    "# dev_dataset = csv.writer(dev_file)\n",
    "# dev_dataset.writerows(dev_data)\n",
    "# dev_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "train_data = []\n",
    "train_file = open('data/train/train_matrix.csv', 'r', newline = '')\n",
    "train_dataset = csv.reader(train_file)\n",
    "for row in train_dataset:\n",
    "    train_data.append(row)\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "dev_data = []\n",
    "dev_file = open('data/dev/dev_matrix.csv', 'r', newline = '')\n",
    "dev_dataset = csv.reader(dev_file)\n",
    "for row in dev_dataset:\n",
    "    dev_data.append(row)\n",
    "dev_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = np.array(dev_data).astype(float)\n",
    "# y_dev = np.array(dev_label).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(train_data)\n",
    "x = x.astype(float)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'source_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'source_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\YLfan\\OneDrive\\UniMelb\\COMP90042\\Rumour-Detection-and-Analysis-on-Twitter\\bert_lstm.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YLfan/OneDrive/UniMelb/COMP90042/Rumour-Detection-and-Analysis-on-Twitter/bert_lstm.ipynb#ch0000015?line=1'>2</a>\u001b[0m y_train \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YLfan/OneDrive/UniMelb/COMP90042/Rumour-Detection-and-Analysis-on-Twitter/bert_lstm.ipynb#ch0000015?line=2'>3</a>\u001b[0m \u001b[39m# f = open('data/dev/dev_pred.txt', 'w')\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/YLfan/OneDrive/UniMelb/COMP90042/Rumour-Detection-and-Analysis-on-Twitter/bert_lstm.ipynb#ch0000015?line=3'>4</a>\u001b[0m \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m train[\u001b[39m'\u001b[39;49m\u001b[39msource_id\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mvalue_counts()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YLfan/OneDrive/UniMelb/COMP90042/Rumour-Detection-and-Analysis-on-Twitter/bert_lstm.ipynb#ch0000015?line=4'>5</a>\u001b[0m x_train \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/YLfan/OneDrive/UniMelb/COMP90042/Rumour-Detection-and-Analysis-on-Twitter/bert_lstm.ipynb#ch0000015?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1895\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/frame.py?line=3502'>3503</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/frame.py?line=3503'>3504</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/frame.py?line=3504'>3505</a>\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/frame.py?line=3505'>3506</a>\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/frame.py?line=3506'>3507</a>\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'source_id'"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "y_train = []\n",
    "# f = open('data/dev/dev_pred.txt', 'w')\n",
    "dict = train['source_id'].value_counts()\n",
    "x_train = []\n",
    "for i in range(1895):\n",
    "    x_train.append(x[index:index+dict[i]])\n",
    "    y_train.append(train['label'][index])\n",
    "    index += dict[i]\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_64 = []\n",
    "for row in x_train:\n",
    "    if len(row) >= 64:\n",
    "        x_train_64.append(row[:64])\n",
    "    else:\n",
    "        temp = np.concatenate((row,[[0] * 768] * (64-len(row))))\n",
    "        x_train_64.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895, 64, 768)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(x_train_64)\n",
    "x = x.astype(float)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(y_train).astype(int)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "y_dev = []\n",
    "# f = open('data/dev/dev_pred.txt', 'w')\n",
    "dict = dev['source_id'].value_counts()\n",
    "x_devl = []\n",
    "for i in range(632):\n",
    "    x_devl.append(x_dev[index:index+dict[i]])\n",
    "    y_dev.append(dev['label'][index])\n",
    "    index += dict[i]\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(632,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dev_64 = []\n",
    "for row in x_devl:\n",
    "    if len(row) >= 64:\n",
    "        x_dev_64.append(row[:64])\n",
    "    else:\n",
    "        temp = np.concatenate((row,[[0] * 768] * (64-len(row))))\n",
    "        x_dev_64.append(temp)\n",
    "x_dev = np.array(x_dev_64)\n",
    "x_dev = x_dev.astype(float)\n",
    "x_dev.shape\n",
    "y_dev = np.array(y_dev).astype(int)\n",
    "y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train['label']).astype(int)\n",
    "y_dev = np.array(dev['label']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30419,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(train_label)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30419, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024, activation='relu', input_dim = 768),\n",
    "    tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.6),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(vocab_size, 300, input_length=maxlen))\n",
    "model.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy', get_f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 768)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 768), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\YLfan\\OneDrive\\UniMelb\\COMP90042\\Rumour-Detection-and-Analysis-on-Twitter\\bert_lstm.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/YLfan/OneDrive/UniMelb/COMP90042/Rumour-Detection-and-Analysis-on-Twitter/bert_lstm.ipynb#ch0000029?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m \u001b[39m128\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(x_dev,y_dev))\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/ProgramData/Miniconda3/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_1\" (type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 768)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 768), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x, y, epochs=10, batch_size = 128, validation_data=(x_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = history.model.predict(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12654859],\n",
       "       [0.02063759],\n",
       "       [0.02118009],\n",
       "       [0.09812991],\n",
       "       [0.05099511],\n",
       "       [0.0104217 ],\n",
       "       [0.01235239],\n",
       "       [0.5913856 ],\n",
       "       [0.03979163],\n",
       "       [0.6963214 ]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nonrumour',\n",
       " 'nonrumour',\n",
       " 'nonrumour',\n",
       " 'nonrumour',\n",
       " 'nonrumour',\n",
       " 'nonrumour',\n",
       " 'nonrumour',\n",
       " 'nonrumour',\n",
       " 'nonrumour',\n",
       " 'nonrumour']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label = []\n",
    "true_label_f = open('data/dev/dev.label.txt', 'r')\n",
    "for line in true_label_f.readlines():\n",
    "    true_label.append(line.strip('\\n'))\n",
    "true_label_f.close()\n",
    "true_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "p_label = []\n",
    "# f = open('data/dev/dev_pred.txt', 'w')\n",
    "dict = dev['source_id'].value_counts()\n",
    "for i in range(632):\n",
    "    if sum(y_pred[index:index+dict[i], 0])/dict[i] > 0.5:\n",
    "    # for p in y_pred[index:index+dict[i], 0]:\n",
    "    #     p_vote = [0, 0]\n",
    "    #     if p > 0.5:\n",
    "    #         p_vote[0] += 1\n",
    "    #     else:\n",
    "    #         p_vote[1] += 1\n",
    "    # if p_vote[0] > p_vote[1]:    \n",
    "        p_label.append('rumour')\n",
    "        # f.write('rumour\\n')\n",
    "    else:\n",
    "        p_label.append('nonrumour')\n",
    "        # f.write('nonrumour\\n')\n",
    "    index += dict[i]\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(true_label, p_label, pos_label='rumour', average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
